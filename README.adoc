ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

# nachgefragt-nachgehakt

## ‚ÑπÔ∏è Introduction:

Hier entsteht unser Projekt

## üìù TODO:

* Welcher Partei geh√∂re ich in den einzelnen Sections an ?
* Welcher Partei stimme ich am meisten zu ?
* Welche Parteien stimmen mir (live) am meisten zu?
- * also eine Art Live-Ansicht mit den aktuell ansprechendsten Parteien
* Detaillierte Einblicke nach Beenden der Umfrage:
- * Wann habe ich welcher Partei zugestimmt
- * Wie antworten die einzelnen Parteien auf die einzelnen Fragen


## Model:

* Es gibt 36 Parteien, 2^5 = 32 < 36 < 64 = 2^6
* Lasse das Model ab 5 beantworteten Fragen bereits mit jeder Frage die Partei erraten, dadurch gewinnt es noch mehr Trainingsdaten
* F√ºr n = 5, ..., 36 gibt es dann zus√§tzliche 31 Inputs pro Partei
* Lasse Nutzer:innen das Model trainieren: 
- * Nutzer:innen beantworten die Fragen
- * Messe, wie lange eine vollst√§ndige der Beantwortung der Fragen dauerte
- * Bestimme den Durchschnitt aller Dauern
- * Bilde ein geeignetes Signifikanzintervall um den Durchschnitt
- * Liegt eine Befragung unterhalb des Signifikanzintervalls, so wird sie beim Training nicht beachtet, aber trotzdem persistiert, um das berechnete Signifikanzintervall zu aktualisieren (Grenzen auf neue durchschnittliche Bearbeitungszeit aktualisieren)
- * Trainiere das Model mit jedem von den Nutzer:innen abgeschickten und validen (inklusive glaubw√ºrdiger Bearbeitungsdauer) Antworten.

## Bisherige Performance:

* Bisher ist das Model in der Lage 32 von 36 Parteien korrekt vorherzusagen:

```javascript
const nn = ml5.neuralNetwork(options);

inputs.forEach(
    (party, index) => {
        nn.addData(party, {output: partiesWithTotalValue[index].name});
    }
)

nn.normalizeData();

const trainingOptions = {
    epochs: 512,
    batchSize: 36
}

/* Saved for later
const modelInfo = {
    model: 'trained_model/model.json',
    metadata: 'trained_model/model_meta.json',
    weights: 'trained_model/model.weights.bin',
};
nn.load(modelInfo, modelLoadedCallback);
function modelLoadedCallback() {}*/

nn.train(trainingOptions, finishedTraining);

function finishedTraining() {
    console.log('Training finished.');
}

function handleResults(error, result) {
    if(error){
      console.error(error);
      return;
    }
    console.log(result); // {label: 'red', confidence: 0.8};
}

// Method to retrieve predictions as table and list
async function classifyWithTable(input) {
    let predictions = (await nn.classify(input, handleResults)).slice(0, 5).map(party => { return {label: party.label, confidence: party.confidence}});
    console.table(predictions);
    return predictions;
}

// Method for testing a single prediction
async function testSinglePrediction(input, expected) {
     return ((await nn.classify(input, handleResults)).slice(0, 1).map(party => { return {label: party.label, confidence: party.confidence}}).pop()).label == expected
}

// Method for testing the whole neural network
async function testNeuralNet() {
    let errors = 0;
    let errorParties = []
    for(let i = 0; i < inputs.length; i++) {
        if(!await testSinglePrediction(inputs[i], partiesWithTotalValue[i].name)) {
            errors++;
            errorParties.push(partiesWithTotalValue[i].name);
        }
    }

    console.log(`${errors} errors while testing ${inputs.length} predictions.`);
    console.log(`The errors occured while trying to predict ${errorParties}`);
}

/* (Result for 256 epochs)
 * 4 errors while testing 36 predictions.
 * The errors occured while trying to predict Tierschutz-allianz,Tierschutz-partei,UNABH√ÑNGIGE,V-Partei¬≥
 */
```
TIP: Fehler traten bei den folgenden Parteien auf: Tierschutz-allianz,Tierschutz-partei,UNABH√ÑNGIGE,V-Partei¬≥

Somit ist unsere KI bisher in der Lage, alle gro√üen Parteien des deutschen Bundestages korrekt zu klassifizieren, allerdings nur, falls die Fragen exakt beantwortet werden. Bisher ist es m√∂glich, die √Ñhnlichkeit zu einer Partei anhand der `Manhattan-Metrik` zu bestimmen. Somit ist nach bisherigem Stand kein neuronales Netz notwendig. Dies wollen wir mit diesem Projekt √§ndern und das neuronale Netz f√ºr das Problem "W√§hlen von Parteien" konkurrenzf√§hig machen.


* Es ist niemals vorgesehen, dass diese Vorhersagen tats√§chlich der Partei entsprechen, welche f√ºr die Person definitiv zutreffend ist.
* Das Ziel ist nicht, f√ºr Personen die richtigen Parteien zu finden, sondern herauszufinden, ob wir eine KI entwickeln k√∂nnen, welche sehr nahe an die Ergebnisse des Wahl-O-Maten herankommen
* Aus diesem Grund stellen wir Nutzer:innen nach der Bearbeitung die folgenden beiden Fragen:
- * 1. Wurde das Ergebnis erwartet?
- * 2. M√∂chte der/die Nutzer:in angeben, welches Ergebnis korrekt gewesen w√§re?
- Dadurch erm√∂glichen wir uns, die Gewichte entsprechend der hier angegebenen Informationen zu trainieren
- * Denn: Wir erhalten die beantworteten Fragen der Nutzer:innen und erhalten durch Frage (2) ein korrektes Label f√ºr diese Antworten
- * Hier ist das Problem: Nutzer:innen k√∂nnten bewusst falsche Angaben machen
- * Falsche Angaben an dieser Stelle lassen sich nur durch einen ausreichend gro√üen vorbereiteten Trainingsdatensatz auffangen.
- * Sammeln wir vor der √∂ffentlichen Nutzung der KI genug Daten, k√∂nnen wir √ºber zus√§tzliches Clustering oder Claasification (KNN z.B.) √ºberpr√ºfen, ob die Antworten nicht zu einer anderen Partei passen w√ºrden
* Eventuell w√§re es ratsam, auf lange Sicht gesehen die KI durch ein Clustering  zus√§tzlich zu unterst√ºtzen
* Dadurch k√∂nnen die Ergebnisse beider Models miteinander verglichen werden

## Optimierung der KI:

* Um das neuronale Netzwerk zu optimieren versuchen wir, dass unaktivierte Neuronen gegebenenfalls aus dem neuronalen Netz entfernt werden.
* Dadurch verringern wir zum Einen die Trainingsdauer erheblich und zum Anderen k√∂nnen dann alle √ºbrigen Gewichte von Beginn des Trainings an besser aktualisiert werden
* Entferne permanent nicht-aktivierte Neuronen aus dem neuronalen Netz, falls diese existieren. Dadurch k√∂nnen Fragen, welche eventuell nichts zu der Classification beitragen entfernt werden
- * Eigentlich ist dieser Ansatz schlecht, da wir die Parteien m√∂glichst √ºber alle Fragen (88 Dimensionen) klassifizieren wollen.
- * Wir k√∂nnten allerdings das verkleinerte Model (entfernte Parameter und Neuronen) als dritte Instanz bei der Entscheidung der Klassifizierung einbauen
- * Dadurch w√ºrden drei Models √ºber die Klassifizierung abstimmen, welche alle jeweils andere Parameter ber√ºcksichtigen (mit gewissen Schnittmengen)
- Die Eingabevektoren (shape[36,88]) k√∂nnten um eine zus√§tzliche Dimension erweitert werden.
- * Diese zus√§tzliche Dimension k√∂nnte m√∂glicherweise ein Score der Partei sein, also einfach die Summe der Antworten auf alle Fragen
- * Es w√§re auch m√∂glich f√ºr jede Kategorie eine zus√§tzliche Dimension hinzuzuf√ºgen, welche jeweils den Score einer Dimension berechnet
- * Hier ist die √úberlegung, ein zus√§tzliches neuronales Netz zu trainieren, welches nur die Scores der Dimensionen und den Gesamtscore einer Partei erf√§hrt.
