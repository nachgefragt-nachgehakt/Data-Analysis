ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

# nachgefragt-nachgehakt

## ‚ÑπÔ∏è Introduction:

Hier entsteht unser Projekt

## üìù TODO:

* Welcher Partei geh√∂re ich in den einzelnen Sections an ?
* Welcher Partei stimme ich am meisten zu ?
* Welche Parteien stimmen mir (live) am meisten zu?
* * also eine Art Live-Ansicht mit den aktuell ansprechendsten Parteien
* Detaillierte Einblicke nach Beenden der Umfrage:
* * Wann habe ich welcher Partei zugestimmt
* * Wie antworten die einzelnen Parteien auf die einzelnen Fragen


## Model:

* Es gibt 36 Parteien, 2^5 = 32 < 36 < 64 = 2^6
* Lasse das Model ab 5 beantworteten Fragen bereits mit jeder Frage die Partei erraten, dadurch gewinnt es noch mehr Trainingsdaten
* F√ºr n = 5, ..., 36 gibt es dann zus√§tzliche 31 Inputs pro Partei
* Lasse Nutzer:innen das Model trainieren: 
* * Nutzer:innen beantworten die Fragen
* * Messe, wie lange eine vollst√§ndige der Beantwortung der Fragen dauerte
* * Bestimme den Durchschnitt aller Dauern
* * Bilde ein geeignetes Signifikanzintervall um den Durchschnitt
* * Liegt eine Befragung unterhalb des Signifikanzintervalls, so wird sie beim Training nicht beachtet, aber trotzdem persistiert, um das berechnete Signifikanzintervall zu aktualisieren (Grenzen auf neue durchschnittliche Bearbeitungszeit aktualisieren)
* * Trainiere das Model mit jedem von den Nutzer:innen abgeschickten und validen (inklusive glaubw√ºrdiger Bearbeitungsdauer) Antworten.

## Bisherige Performance:

* Bisher ist das Model in der Lage 32 von 36 Parteien korrekt vorherzusagen
* Es ist niemals vorgesehen, dass diese Vorhersagen tats√§chlich der Partei entsprechen, welche f√ºr die Person definitiv zutreffend ist.
* Das Ziel ist nicht, f√ºr Personen die richtigen Parteien zu finden, sondern herauszufinden, ob wir eine KI entwickeln k√∂nnen, welche sehr nahe an die Ergebnisse des Wahl-O-Maten herankommen
* Aus diesem Grund stellen wir Nutzer:innen nach der Bearbeitung die folgenden beiden Fragen:
* * 1. Wurde das Ergebnis erwartet?
* * 2. M√∂chte der/die Nutzer:in angeben, welches Ergebnis korrekt gewesen w√§re?
* Dadurch erm√∂glichen wir uns, die Gewichte entsprechend der hier angegebenen Informationen zu trainieren
* * Denn: Wir erhalten die beantworteten Fragen der Nutzer:innen und erhalten durch Frage (2) ein korrektes Label f√ºr diese Antworten
* * Hier ist das Problem: Nutzer:innen k√∂nnten bewusst falsche Angaben machen
* * Falsche Angaben an dieser Stelle lassen sich nur durch einen ausreichend gro√üen vorbereiteten Trainingsdatensatz auffangen.
* * Sammeln wir vor der √∂ffentlichen Nutzung der KI genug Daten, k√∂nnen wir √ºber zus√§tzliches Clustering oder Claasification (KNN z.B.) √ºberpr√ºfen, ob die Antworten nicht zu einer anderen Partei passen w√ºrden
* Eventuell w√§re es ratsam, auf lange Sicht gesehen die KI durch ein Clustering  zus√§tzlich zu unterst√ºtzen
* Dadurch k√∂nnen die Ergebnisse beider Models miteinander verglichen werden

## Optimierung der KI:

* Um das neuronale Netzwerk zu optimieren versuchen wir, dass unaktivierte Neuronen gegebenenfalls aus dem neuronalen Netz entfernt werden.
* Dadurch verringern wir zum Einen die Trainingsdauer erheblich und zum Anderen k√∂nnen dann alle √ºbrigen Gewichte von Beginn des Trainings an besser aktualisiert werden
* Entferne permanent nicht-aktivierte Neuronen aus dem neuronalen Netz, falls diese existieren. Dadurch k√∂nnen Fragen, welche eventuell nichts zu der Classification beitragen entfernt werden
* * Eigentlich ist dieser Ansatz schlecht, da wir die Parteien m√∂glichst √ºber alle Fragen (88 Dimensionen) klassifizieren wollen.
* * Wir k√∂nnten allerdings das verkleinerte Model (entfernte Parameter und Neuronen) als dritte Instanz bei der Entscheidung der Klassifizierung einbauen
* * Dadurch w√ºrden drei Models √ºber die Klassifizierung abstimmen, welche alle jeweils andere Parameter ber√ºcksichtigen (mit gewissen Schnittmengen)
* Die Eingabevektoren (shape[36,88]) k√∂nnten um eine zus√§tzliche Dimension erweitert werden.
* * Diese zus√§tzliche Dimension k√∂nnte m√∂glicherweise ein Score der Partei sein, also einfach die Summe der Antworten auf alle Fragen
* * Es w√§re auch m√∂glich f√ºr jede Kategorie eine zus√§tzliche Dimension hinzuzuf√ºgen, welche jeweils den Score einer Dimension berechnet
* * Hier ist die √úberlegung, ein zus√§tzliches neuronales Netz zu trainieren, welches nur die Scores der Dimensionen und den Gesamtscore einer Partei erf√§hrt.
